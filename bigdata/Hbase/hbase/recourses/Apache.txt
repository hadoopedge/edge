=======================================================Put=======================================================
create't','cf'
list'test'
put'test','row1','cf:a','value1'
put'test','row2','cf:b','value2'
put'test','row3','cf:c','value3'
put ‘t1’, ‘r1’, ‘c1’, ‘value’, ts1
put 'emp, ,'10002','name:name_first','koushik','1514877409217'
get'test','row1'
=======================================================Misc=======================================================
status
status'simple'
status'summary'
status'detailed'
version
whoami
describe't1'
disable't1'
disable_all't.*'
is_disabled't1'
drop't1'
drop_all't.*'
enable't1'
enable_all't.*'
is_enabled't1'
exists't1'
list
list't.*'
show_filters
truncate't1'
=======================================================Create======================================================= 
create't1', {NAME =>'f1', VERSIONS => 5}
t =  create't1', {NAME =>'f1', VERSIONS => 5}
disable't1'
drop't1'
create't1', {NAME =>'f1'}, {NAME =>'f2'}, {NAME =>'f3'}
disable't1'
drop't1'
create't1','f1','f2','f3'
disable't1'
drop't1'
create't1', {NAME =>'f1', VERSIONS => 1, TTL => 2592000, BLOCKCACHE => true}
disable't1'
drop't1'
create't1',NAME =>'f2'
create't1', {NAME =>'f1', VERSIONS => 5}
create't1', {NAME =>'f1'}, {NAME =>'f2'}, {NAME =>'f3'}
create't1','f1','f2','f3'
create't1', {NAME =>'f1', VERSIONS => 1, TTL => 2592000, BLOCKCACHE => true}
create't1', {NAME =>'f1', CONFIGURATION => {'hbase.hstore.blockingStoreFiles'=>'10'}}
create'emp1', {NAME =>'name', VERSIONS => 5}, {NAME =>'date', VERSIONS => 5}, {NAME =>'sex', VERSIONS => 5}
=======================================================alter=======================================================
alter't1', NAME =>'f1', VERSIONS => 5
alter't1','f1', {NAME =>'f2', IN_MEMORY => true}, {NAME =>'f3', VERSIONS => 5}
alter't1', NAME =>'f1', METHOD =>'delete'
alter't1','delete'=>'f1'
alter't1', MAX_FILESIZE =>'134217728'
#alter't1','coprocessor'=>'hdfs:///foo.jar|com.foo.FooRegionObserver|1001|arg1=1,arg2=2'
#[coprocessor jar file location] | class name | [priority] | [arguments]
#alter't1', CONFIGURATION => {'hbase.hregion.scan.loadColumnFamiliesOnDemand'=>'true'}
#alter't1', {NAME =>'f2', CONFIGURATION => {'hbase.hstore.blockingStoreFiles'=>'10'}}
#alter't1', METHOD =>'table_att_unset', NAME =>'MAX_FILESIZE'
#alter't1', METHOD =>'table_att_unset', NAME =>'coprocessor$1'
#alter't1', { NAME =>'f1', VERSIONS => 3 },{ MAX_FILESIZE =>'134217728'}, { METHOD =>'delete', NAME =>'f2'},OWNER =>'johndoe', METADATA => {'mykey'=>'myvalue'}
alter_status't1'
alter_async't1', NAME =>'f1', METHOD =>'delete'
alter_async't1','delete'=>'f1'
alter't1', METHOD =>'table_att', MAX_FILESIZE =>'67108864'
alter't1', {NAME =>'f1'}, {NAME =>'f2', METHOD =>'delete'}
count't1', INTERVAL => 100000
count't1', CACHE => 1000
//alter't1','f1', {NAME =>'f2', IN_MEMORY => true}, {NAME =>'f3', VERSIONS => 5}
count'emp', INTERVAL => 10, CACHE => 1000
t.count INTERVAL => 100000
t.count CACHE => 1000
t.count INTERVAL => 10, CACHE => 1000
delete'table','row', 'column', timestamp
# 10020      column=name:name_first, timestamp=1514728559287, value=Mayuko   
delete'emp','10019','name:name_first',  1514728606285
t.delete'r1','c1', ts1
delete'emp','10019','name:name_last'
deleteall'emp','10019'
deleteall'emp','10017' 1514728606285
alter'emp','name', {NAME =>'date',  VERSIONS => 5}
#deleteall't1','r1','c1'
#deleteall'emp','10007','name', 1514737638997

=======================================================get=======================================================

get'emp','10001'
get'emp','10001', {TIMERANGE => [1414774642671, 1614737638999], VERSIONS => 4}
get'emp','10002','name'
get'emp','10002', {COLUMN =>'name', TIMESTAMP => 1514774642671} // will return value if only, there is a value stored with the same TIMESTAMP.
get'emp','10002', {COLUMN =>'name',  VERSIONS => 4}// will return 4 latest values.
get'emp','10002', {COLUMN =>'name', TIMERANGE =>  [1414737638777, 1614737638999]} // will return one set of values which is latest between the TIMERANGE.
get'emp','10002', {COLUMN =>'name', TIMERANGE =>  [1414737638777, 1614737638999], VERSIONS => 4} // will return all the  values, between the TIMERANGE.
get'emp','10002', {COLUMN =>['name','date'] , TIMERANGE =>  [1414774642671, 1614737638999], VERSIONS => 4}
get'emp','10002', {COLUMN =>['name','date'] , TIMERANGE =>  [1414774642671, 1614737638999], VERSIONS => 4} 
t =  get_table'emp'
t.get'10002'
t.get'10002', {TIMERANGE => [1414537960807, 1614537960807]}
t.get'10002', {COLUMN =>'name'}
t.get'10002', {COLUMN => ['name','date','sex']}
t.get'10002', {COLUMN =>'name', TIMESTAMP => 1514537927138}
t.get'10002', {COLUMN =>'name', TIMERANGE => [1414537960807, 1614537960807], VERSIONS => 4}
#t.get'10002', {COLUMN =>'name', TIMESTAMP => 1514537927138, VERSIONS => 4}//didnt work with any time other than the exact TIMESTAMP.
t.get'10002', {FILTER => "ValueFilter(=,'binary:Bezalel')"}
t.get'10002','name'
t.get'10002','name','date'
t.get'10002', ['name','date']
get  'hbase:meta' , 'emp,,1514537886246.768fe78ebbfa3200493aeafc79f09650.'
COLUMN                                    CELL                                                                                                                   
 info:regioninfo                          timestamp=1514789117541, value={ENCODED => 768fe78ebbfa3200493aeafc79f09650, NAME => 'emp,,1514537886246.768fe78ebbfa3200493aeafc79f09650.', STARTKEY => '', ENDKEY => ''}                                                                    
 info:seqnumDuringOpen                    timestamp=1514789117541, value=\x00\x00\x00\x00\x00\x00\x00\x09                                                        
 info:server                              timestamp=1514789117541, value=localhost:16201                                                                         
 info:serverstartcode                     timestamp=1514789117541, value=1514789091463   
=======================================================scan=======================================================

scan'hbase:meta', {COLUMNS =>'info:regioninfo'}
scan'emp', {COLUMNS =>'name'}
scan'emp', {COLUMNS =>'name:name_first'}
scan'emp', {COLUMNS =>'name:name_first',LIMIT => 10}
scan'emp', {COLUMNS =>'name:name_first',LIMIT => 10,STARTROW =>'10007', TIMERANGE => [1414537927138, 1614537927138], VERSIONS => 4}
scan'emp', {FILTER => "PrefixFilter ('1000') AND QualifierFilter (=,'binary:name_first')"}
scan'emp', {FILTER => "PrefixFilter ('1000') AND QualifierFilter (=,'binary:name_first') AND TimestampsFilter ( 1414537927138, 1514537927138)"}
scan'emp', {COLUMNS => ['name:name_first','date:date_birth'], CACHE_BLOCKS => false}
scan'emp', {RAW => true, VERSIONS => 10}
scan'emp',  {COLUMNS => ['name:name_first:toInt','date:date_birth:c(org.apache.hadoop.hbase.util.Bytes).toInt'] }/in place of "org.apache.hadoop.hbase.util.Bytes" custom classes can be used.
=======================================================delete=======================================================
A delete can apply to a complete row, a complete column family, or to just one column. It is only in the last case that you can delete versions at a specific timestamp. For the deletion of a row or all the columns within a family, it always works by deleting all cells older than a certain time.

let’s suppose we want to delete a row. For this you can specify a timestamp, or else by default the currentTimeMillis is used. What this means is “delete all cells where the timestamp is less than or equal to this timestamp”. HBase never modifies data in place, so for example a delete will not immediately delete (or mark as deleted) the entries in the storage file that correspond the delete condition. Rather, a so-called “tombstone” is written, which will mask the deleted values. When HBase does a major compaction, the tombstones are processed to actually remove the dead values, together with the tombstones themselves.

If the timestamp you specified when deleting a row is larger than the timestamp of any value in the row, then you can consider the complete row to be deleted.
=======================================================special=======================================================


compact'TABLENAME'
compact'REGIONNAME'
compact'REGIONNAME','cf1'
compact'TABLENAME','cf1'
flush'TABLENAME'
flush'REGIONNAME'
major_compact't1'
major_compact'r1'
major_compact'r1','cf1'
major_compact't1','c1'

import java.text.SimpleDateFormat
import java.text.ParsePosition
SimpleDateFormat.new("yy/MM/dd HH:mm:ss").parse("08/08/16 20:56:29", ParsePosition.new(0)).getTime()
import java.util.Date
 Date.new(1218920189000).toString()
